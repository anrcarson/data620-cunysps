{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 620 Project 3\n",
    "## Every Student in CUNY SPS's Summer 2018 DATA 620 class\n",
    "\n",
    "Collaborating together as a single group, the class was tasked with building the best name gender classifier we could."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names\n",
    "from nltk.classify import apply_features\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `nltk` library was of the utmost importance in this project; it was used for the names corpus and for its classifiers. The library `random` was used for shuffling the names, and `pandas` was used for creating a function to test the accuracy of the final gender-predicting function more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "[(name, 'female') for name in names.words('female.txt')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names provided by `nltk` were utilized for training and testing our algorithms, with male and female names being stored in a single variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determination of accuracy\n",
    "\n",
    "Most of the class utilized the Naive Bayes method, and so, when creating a function for determining the accuracy of any given combination of features, it was determined the Naive Bayes method of classification would be used once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(number_of_runs, function_to_use):\n",
    "    acc_df = {\n",
    "        \"classifier\": [],\n",
    "        \"train_set_accuracy\": [],\n",
    "        \"test_set_accuracy\": [],\n",
    "        \"devtest_set_accuracy\": [],\n",
    "        \"devtest_errors\": []\n",
    "    }\n",
    "    for i in range(number_of_runs):\n",
    "        random.shuffle(names)\n",
    "        acc_train_names = names[1000:]\n",
    "        acc_devtest_names = names[500:1000]\n",
    "        acc_test_names = names[:500]\n",
    "        acc_train_set = [(function_to_use(n), g) for (n,g) in acc_train_names]\n",
    "        acc_devtest_set = [(function_to_use(n), g) for (n,g) in acc_devtest_names]\n",
    "        acc_test_set = [(function_to_use(n), g) for (n,g) in acc_test_names]\n",
    "        acc_classifier = nltk.NaiveBayesClassifier.train(acc_train_set)\n",
    "        acc_df[\"classifier\"].append(acc_classifier)\n",
    "        acc_df[\"train_set_accuracy\"].append(nltk.classify.accuracy(acc_classifier, acc_train_set))\n",
    "        acc_df[\"test_set_accuracy\"].append(nltk.classify.accuracy(acc_classifier, acc_test_set))\n",
    "        acc_df[\"devtest_set_accuracy\"].append(nltk.classify.accuracy(acc_classifier, acc_devtest_set))\n",
    "        acc_errors = []\n",
    "        for (name, tag) in acc_devtest_names:\n",
    "            acc_guess = acc_classifier.classify(function_to_use(name))\n",
    "            if acc_guess != tag:\n",
    "                acc_errors.append( (tag, acc_guess, name) )\n",
    "        acc_df[\"devtest_errors\"].append(acc_errors)\n",
    "    acc_df = pd.DataFrame.from_dict(acc_df)\n",
    "    return(acc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was decided that a dictionary - later to be transformed into a data frame - would be created to store the number of runs performed for the given created function for checking features against the names in the `names` variable. This is why this function, `accuracy`, has a parameter called `number_of_runs`, so that the class could determine how many times a given function should be run before being considered accurate. Ultimately the number settled on was 100.\n",
    "\n",
    "Within the accuracy function itself the names were shuffled for every run; for each shuffling of the names, the first 500 names would be used as a test set, the next 500 for the dev test, and the remaining names for the training set. The classifiers for each run were kept, as were the list of errors.\n",
    "\n",
    "Lastly, the data frame would be returned, best stored in another user-defined variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender features\n",
    "\n",
    "**Natural Language Processing with Python**, Chapter 6, provided two premade functions with features to check against the corpus of names. The class made a third function to compare against the accuracy of with the textbook's examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textbook_gender_features_1(word):\n",
    "    return {'last_letter': word[-1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the textbook's first example of testing for gender features. All it tests for is the last letter of the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textbook_gender_features_2(name):\n",
    "    features = {}\n",
    "    features[\"firstletter\"] = name[0].lower()\n",
    "    features[\"lastletter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count(%s)\" % letter] = name.lower().count(letter)\n",
    "        features[\"has(%s)\" % letter] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the textbook's second example of testing for gender features. It expands upon the previous example by checking for the last letter of a given name, but also by looking into the first letter, the number of times each letter appears, and whether or not the letter was present in the name at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_gender_features(name):\n",
    "    features = {}\n",
    "    temp_name = name\n",
    "    eng_cons_clusters = [\"bl\", \"br\", \"ch\", \"cl\", \"cr\", \"dr\", \"fl\", \"fr\", \"gl\", \"gr\", \"pl\", \"pr\", \"sc\", \"sh\", \"sk\", \"sl\", \"sm\", \"sn\", \"sp\", \"st\", \"sw\", \"th\", \"tr\", \"tw\", \"wh\", \"wr\", \"sch\", \"scr\", \"shr\", \"sph\", \"spl\", \"spr\", \"squ\", \"str\", \"thr\"]\n",
    "    features[\"firstletter\"] = name[0].lower() \n",
    "    features[\"lastletter\"] = name[-1].lower() \n",
    "    features[\"prefix\"] = name[:3].lower() if len(name) > 4 else name[:2].lower() \n",
    "    features[\"suffix\"] = name[-3:].lower() if len(name) > 4 else name[-2:].lower()\n",
    "    clusters = []\n",
    "    for cluster in eng_cons_clusters[::-1]:\n",
    "        if cluster in temp_name:\n",
    "            temp_name = temp_name.replace(cluster, \"\")\n",
    "            clusters.append(cluster)\n",
    "    features[\"english_consonant_clusters_1\"] = clusters[0] if len(clusters) > 0 else None\n",
    "    features[\"english_consonant_clusters_2\"] = clusters[1] if len(clusters) > 1 else None\n",
    "    features[\"english_consonant_clusters_3\"] = clusters[2] if len(clusters) > 2 else None\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the class's function. It utilizes the first and last letter from the previous text book, but it also looks for the prefix and suffix - or first and last two or three letters, depending on the name's length - of a name and looks for whether or not any of the consonant clusters in English are present.\n",
    "\n",
    "### Honorable mentions\n",
    "\n",
    "The class had also attempted functions that looked into the\n",
    "\n",
    "* letter order\n",
    "* first, second, and third letter at the beginning;\n",
    "* first, second, and third letter at the end;\n",
    "* first two letters;\n",
    "* first three letters;\n",
    "* last two letters;\n",
    "* last three letters;\n",
    "* double letters;\n",
    "* combination of letters (any);\n",
    "* last letter - if it was \"y\", \"a\", \"e\", \"i\", \"k\", \"o\", \"r\", \"s\", \"t\"\n",
    "* number of syllables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing accuracy\n",
    "\n",
    "The hope for our class when it came to this project was to beat out the accuracy of the gender feature functions provided by the textbook. To do so, we ran each function 100 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_set_accuracy</th>\n",
       "      <th>test_set_accuracy</th>\n",
       "      <th>devtest_set_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.762863</td>\n",
       "      <td>0.762660</td>\n",
       "      <td>0.760740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001756</td>\n",
       "      <td>0.016983</td>\n",
       "      <td>0.018034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.758641</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.716000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.761521</td>\n",
       "      <td>0.756000</td>\n",
       "      <td>0.746000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.762673</td>\n",
       "      <td>0.764000</td>\n",
       "      <td>0.764000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.763969</td>\n",
       "      <td>0.772000</td>\n",
       "      <td>0.772000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.804000</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_set_accuracy  test_set_accuracy  devtest_set_accuracy\n",
       "count          100.000000         100.000000            100.000000\n",
       "mean             0.762863           0.762660              0.760740\n",
       "std              0.001756           0.016983              0.018034\n",
       "min              0.758641           0.710000              0.716000\n",
       "25%              0.761521           0.756000              0.746000\n",
       "50%              0.762673           0.764000              0.764000\n",
       "75%              0.763969           0.772000              0.772000\n",
       "max              0.766993           0.804000              0.810000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textbook_df_1 = accuracy(100, textbook_gender_features_1)\n",
    "textbook_df_1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function, while simplistic, has fairly impressive results; the average accuracy across the board is between 76.1% and 76.2%. It showed us that less could be more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_set_accuracy</th>\n",
       "      <th>test_set_accuracy</th>\n",
       "      <th>devtest_set_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.778436</td>\n",
       "      <td>0.771020</td>\n",
       "      <td>0.773940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.016616</td>\n",
       "      <td>0.018594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.773906</td>\n",
       "      <td>0.728000</td>\n",
       "      <td>0.726000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.777506</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.763500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.778226</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.773000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.779666</td>\n",
       "      <td>0.780500</td>\n",
       "      <td>0.784000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.783122</td>\n",
       "      <td>0.812000</td>\n",
       "      <td>0.822000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_set_accuracy  test_set_accuracy  devtest_set_accuracy\n",
       "count          100.000000         100.000000            100.000000\n",
       "mean             0.778436           0.771020              0.773940\n",
       "std              0.001988           0.016616              0.018594\n",
       "min              0.773906           0.728000              0.726000\n",
       "25%              0.777506           0.760000              0.763500\n",
       "50%              0.778226           0.770000              0.773000\n",
       "75%              0.779666           0.780500              0.784000\n",
       "max              0.783122           0.812000              0.822000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textbook_df_2 = accuracy(100, textbook_gender_features_2)\n",
    "textbook_df_2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second function provided by the textbook, while slightly more complex, had an average accuracy across the board that ranged from 77.1% to 77.8%. This showed the class that looking into a few more features could produce a substantial increase in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_set_accuracy</th>\n",
       "      <th>test_set_accuracy</th>\n",
       "      <th>devtest_set_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.883759</td>\n",
       "      <td>0.834940</td>\n",
       "      <td>0.828000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.017847</td>\n",
       "      <td>0.017167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.879752</td>\n",
       "      <td>0.786000</td>\n",
       "      <td>0.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.882488</td>\n",
       "      <td>0.821500</td>\n",
       "      <td>0.815500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.883713</td>\n",
       "      <td>0.834000</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.884937</td>\n",
       "      <td>0.846500</td>\n",
       "      <td>0.838500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.864000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_set_accuracy  test_set_accuracy  devtest_set_accuracy\n",
       "count          100.000000         100.000000            100.000000\n",
       "mean             0.883759           0.834940              0.828000\n",
       "std              0.001636           0.017847              0.017167\n",
       "min              0.879752           0.786000              0.790000\n",
       "25%              0.882488           0.821500              0.815500\n",
       "50%              0.883713           0.834000              0.830000\n",
       "75%              0.884937           0.846500              0.838500\n",
       "max              0.887097           0.882000              0.864000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_df = accuracy(100, class_gender_features)\n",
    "class_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class's function was more complex than what the textbook offered. It resulted in an average accuracy of 82.8% to 88.3%, and sometimes even higher depending on the run. It succeeded in overcoming the results the textbook provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In conclusion, through working together and challenging each other, a group of well-over 20 students managed to come up with a list of features to pair against the names corpus provided by the `nltk` library that challenged *and* defeated the accuracy of those provided by our class's textbook by more than 5%. This is exactly what we expected of our final function as we set out with the personal goals of beating the textbook's provided functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
